{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a2f6c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prave\\Sentiment_Analysis\\.venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf### models\n",
    "import numpy as np### math computations\n",
    "import matplotlib.pyplot as plt### plotting bar chart\n",
    "import sklearn### machine learning library\n",
    "from sklearn.metrics import confusion_matrix, roc_curve### metrics\n",
    "import seaborn as sns### visualizations\n",
    "import datetime\n",
    "import pathlib\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "from numpy import random\n",
    "import gensim.downloader as api\n",
    "from PIL import Image\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import (Dense,Flatten,SimpleRNN,InputLayer,Conv1D,Bidirectional,GRU,LSTM,BatchNormalization,Dropout,Input, Embedding,TextVectorization)\n",
    "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe333717",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b3b00f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = tfds.load('imdb_reviews', split = ['train', 'test[:50%]', 'test[50%:]'],as_supervised = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25944e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38e54556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"There are films that make careers. For George Romero, it was NIGHT OF THE LIVING DEAD; for Kevin Smith, CLERKS; for Robert Rodriguez, EL MARIACHI. Add to that list Onur Tukel's absolutely amazing DING-A-LING-LESS. Flawless film-making, and as assured and as professional as any of the aforementioned movies. I haven't laughed this hard since I saw THE FULL MONTY. (And, even then, I don't think I laughed quite this hard... So to speak.) Tukel's talent is considerable: DING-A-LING-LESS is so chock full of double entendres that one would have to sit down with a copy of this script and do a line-by-line examination of it to fully appreciate the, uh, breadth and width of it. Every shot is beautifully composed (a clear sign of a sure-handed director), and the performances all around are solid (there's none of the over-the-top scenery chewing one might've expected from a film like this). DING-A-LING-LESS is a film whose time has come.\", shape=(), dtype=string)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(b\"A blackly comic tale of a down-trodden priest, Nazarin showcases the economy that Luis Bunuel was able to achieve in being able to tell a deeply humanist fable with a minimum of fuss. As an output from his Mexican era of film making, it was an invaluable talent to possess, with little money and extremely tight schedules. Nazarin, however, surpasses many of Bunuel's previous Mexican films in terms of the acting (Francisco Rabal is excellent), narrative and theme.<br /><br />The theme, interestingly, is something that was explored again in Viridiana, made three years later in Spain. It concerns the individual's struggle for humanity and altruism amongst a society that rejects any notion of virtue. Father Nazarin, however, is portrayed more sympathetically than Sister Viridiana. Whereas the latter seems to choose charity because she wishes to atone for her (perceived) sins, Nazarin's whole existence and reason for being seems to be to help others, whether they (or we) like it or not. The film's last scenes, in which he casts doubt on his behaviour and, in a split second, has to choose between the life he has been leading or the conventional life that is expected of a priest, are so emotional because they concern his moral integrity and we are never quite sure whether it remains intact or not.<br /><br />This is a remarkable film and I would urge anyone interested in classic cinema to seek it out. It is one of Bunuel's most moving films, and encapsulates many of his obsessions: frustrated desire, mad love, religious hypocrisy etc. In my view 'Nazarin' is second only to 'The Exterminating Angel', in terms of his Mexican movies, and is certainly near the top of the list of Bunuel's total filmic output.\", shape=(), dtype=string)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for review, label in val_ds.take(2):\n",
    "    print(review)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0e69e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    no_tag = tf.strings.regex_replace(lowercase, \"<[^>]+>\",\"\")\n",
    "    output = tf.strings.regex_replace(no_tag,\"[%s]\"%re.escape(string.punctuation),\"\")\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "517642fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'in the movie man called t\\xc3\\xa9v\\xc3\\xa8z went to a friend\\xe2\\x80\\x99s plce and they had a tensed discussion i don\\xe2\\x80\\x99t love this movie would you t'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardization(tf.constant(\"<u>In the movie?, </u>man called Tévèz, went to a friend’s pl**ce and they had a tensed discussion. I don’t love this movie! would you?<br> <br /><br />T\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96f8fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE=10000\n",
    "SEQUENCE_LENGTH=250\n",
    "EMBEDDING_DIM=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24881111",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = TextVectorization(\n",
    "    standardize = standardization,\n",
    "    max_tokens = VOCAB_SIZE,\n",
    "    output_mode = 'int',\n",
    "    output_sequence_length = SEQUENCE_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c6f87a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = train_ds.map(lambda x,y:x)\n",
    "vectorize_layer.adapt(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cb0f51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorize_layer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2cf3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(review,label):\n",
    "    return vectorize_layer(review),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0923659",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=train_ds.map(vectorizer)\n",
    "val_dataset=val_ds.map(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77989e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.str_('absolutely')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()[411]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "116ae63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[  10   13   33  411  384   17   89   26    1    8   32 1337 3521   40\n",
      "  491    1  192   22   84  149   18   10  215  317   26   64  239  212\n",
      "    8  484   54   64   84  111   95   21 5502   10   91  637  737   10\n",
      "   17    7   33  393 9554  169 2443  406    2   87 1205  135   65  142\n",
      "   52    2    1 7408   65  245   64 2832   16    1 2851    1    1 1415\n",
      " 4969    3   39    1 1567   15 3521   13  156   18    4 1205  881 7874\n",
      "    8    4   17   12   13 4037    5   98  145 1234   11  236  696   12\n",
      "   48   22   91   37   10 7285  149   37 1337    1   49  396   11   95\n",
      " 1148  841  140    9    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0], shape=(250,), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for review,label in train_dataset.take(1):\n",
    "  print(review)\n",
    "  print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f673256",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=train_dataset.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_dataset=val_dataset.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cbbece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
